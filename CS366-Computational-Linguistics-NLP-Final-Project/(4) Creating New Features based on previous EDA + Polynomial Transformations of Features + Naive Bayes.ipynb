{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Import Libraries and Read in Files"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import PolynomialFeatures","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Read in Data with meta featured in it\n\ndf = pd.read_csv(\"../input/cs366-full-data/data_meta_feat_added_drop_all_missing.csv\", index_col=0)","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reindex for better / easier concatenation later\ndf.reset_index(inplace=True)\ndel df['index']","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Dividing data into real, fake and sarcasm data for easier n-gram visualizations\n\n# df_real = df.copy()[df.target=='real']\n# df_fake = df.copy()[df.target=='fake']\n# df_sarc = df.copy()[df.target=='sarcasm']","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Creating new features based on EDA"},{"metadata":{},"cell_type":"markdown","source":"#### Features from title_cc EDA"},{"metadata":{},"cell_type":"markdown","source":"- Based on the kdeplot for \"title_cc\", we saw that there are two bins where the density distributions of the three types of news did not match\n    - One bin was the 45-60 range where fake news had the highest density for character counts followed by real and sarcastic news. \n    - Another bin was the 60 to 70ish range where sarcastic news had the highest density for character counts followed by real and fake news. We will create two new features that indicate whether the number of characters fall under these bins (1 yes, 0 no)."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['title_cc_45_60'] = np.where((df.title_cc > 45) & (df.title_cc < 60), 1, 0)\ndf['title_cc_60_70'] = np.where((df.title_cc > 60) & (df.title_cc < 70), 1, 0)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### Features from word count and unique word count"},{"metadata":{},"cell_type":"markdown","source":"Similar to how we created features from the kdeplot of title_cc, we focus on the ranges where the distributions of word count and unique word count do not match across the three different types of news"},{"metadata":{"trusted":true},"cell_type":"code","source":"# unique word count 7 to 9 yes or no?\ndf['title_unique_wc_7_9'] = np.where((df.title_unique_wc >= 7) & (df.title_unique_wc <= 9), 1, 0)\n\n# word count 6 to 9 or no?\ndf['title_wc_6_9'] = np.where((df.title_wc >= 6) & (df.title_wc <= 9), 1, 0)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#### Features from Average Word Length "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Title Average Word Length 4.0 - 4.1 yes or no?\ndf['title_mean_wl_4.0_4.1'] = np.where((df.title_mean_wl >= 4.0) & (df.title_mean_wl <= 4.1), 1, 0)\n\n# Title Average Word Length 4.9 - 5.0 yes or no\ndf['title_mean_wl_4.9_5.0'] = np.where((df.title_mean_wl >= 4.9) & (df.title_mean_wl <= 5.0), 1, 0)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Features from Median Word Length "},{"metadata":{"trusted":true},"cell_type":"code","source":"df['title_median_wl_5'] = np.where((df.title_median_wl <= 5), 1, 0)","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Feature from TF-IDF Based Wordcloud for Sarcastic News"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Top 8 words identified to be important words for sarcasm news based on tf-idf weighting\n\nsarcasm_tfidf_words = [\"election\",\"as\",\"gop\",\"eliminates\",\"commission\",\"fear\",\"fraud\"]","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Making 8 new columns that indicate whether each sarcasm new word is in each title\n\nfor sarc_word in sarcasm_tfidf_words:\n    df[\"word_\" + sarc_word+\"_included\"] = np.where(df.title.str.contains(sarc_word), 1, 0)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a new column \ndf['sarc_tfidf_wc'] = \\\ndf['word_election_included'] + df['word_as_included'] + df['word_gop_included'] + df['word_eliminates_included'] + df['word_commission_included'] +\\\ndf['word_fear_included'] + df['word_fraud_included']","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop the sarcasm word indicator variable\nfor sarc_word in sarcasm_tfidf_words:\n    del df[\"word_\" + sarc_word+\"_included\"]","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare Data for ML (e.g. Countvectorize, split data to train and test data etc.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['url'] # drop url column","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n-gram features\n\ncountvec = CountVectorizer(ngram_range=(1,3),max_features=1000,analyzer='word')\ncountvec_features = countvec.fit_transform(df['title'])\nlabels = df['target'].replace({'real':0,'fake':1,'sarcasm':2})","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n-gram features + All Meta Features I created\ncountvec_meta_features = pd.concat([df.iloc[:,2:], pd.DataFrame(countvec_features.toarray())], axis=1)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# wf-idf features (using sublinear_tf = True where wf = 1+ log(tf))\ntfidf = TfidfVectorizer(sublinear_tf = True, ngram_range=(1,3),max_features=1000,analyzer='word')\ntfidf_features = tfidf.fit_transform(df['title'])","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# wf-idf + All Meta Features I created\ntfidf_meta_features = pd.concat([df.iloc[:,2:], pd.DataFrame(tfidf_features.toarray())], axis=1)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### NB on All Features I created + n-gram features"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_ngram = MultinomialNB()\n\nprint(\"Naive Bayes on n-gram+all meta feats: CV Balanced Accuracy \", cross_val_score(nb_ngram, countvec_meta_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\nprint(\"Naive Bayes on n-gram+all meta feats: CV AUC Score \", cross_val_score(nb_ngram, countvec_meta_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\nprint(\"Naive Bayes on n-gram+all meta feats: CV Weighted F1 Score \", cross_val_score(nb_ngram, countvec_meta_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":31,"outputs":[{"output_type":"stream","text":"Naive Bayes on n-gram+all meta feats: CV Balanced Accuracy  0.37002259180718616\nNaive Bayes on n-gram+all meta feats: CV AUC Score  0.582400539231516\nNaive Bayes on n-gram+all meta feats: CV Weighted F1 Score  0.5417892842699839\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### NB on All Features I created + tf-idf features"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_tfidf_meta = MultinomialNB()\n\n\nprint(\"Naive Bayes on wfidf+meta feats: CV Balanced Accuracy \", \n      cross_val_score(nb_tfidf_meta, tfidf_meta_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\nprint(\"Naive Bayes on wfidf+meta feats: CV AUC Score \", \n      cross_val_score(nb_tfidf_meta, tfidf_meta_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\nprint(\"Naive Bayes on wfidf+meta feats: CV Weighted F1 Score \", \n      cross_val_score(nb_tfidf_meta, tfidf_meta_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":20,"outputs":[{"output_type":"stream","text":"Naive Bayes on wfidf+meta feats: CV Balanced Accuracy  0.35967446007567505\nNaive Bayes on wfidf+meta feats: CV AUC Score  0.5790361777859548\nNaive Bayes on wfidf+meta feats: CV Weighted F1 Score  0.5503809449357993\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### NB on n-grams feats + meta features I created on which polynomial transformation was applied"},{"metadata":{"trusted":true},"cell_type":"code","source":"poly = PolynomialFeatures(degree=2)\nmeta_poly_feats = poly.fit_transform(df.iloc[:,2:])","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"poly_feat_names = ['x'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(df.iloc[:,2:].columns,p) for p in poly.powers_]]\nmeta_poly_feats = pd.DataFrame(meta_poly_feats, columns = poly_feat_names)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n-gram features + All Meta Features I created with polynomial transformations\ncountvec_meta_poly_features = pd.concat([meta_poly_feats, pd.DataFrame(countvec_features.toarray())], axis=1)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"After polynomial transformation, number of features increased from {} to {}\".format(countvec_meta_features.shape[1], countvec_meta_poly_features.shape[1]))","execution_count":36,"outputs":[{"output_type":"stream","text":"After polynomial transformation, number of features increased from 1015 to 1136\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_ngram2 = MultinomialNB()\n\nprint(\"Naive Bayes on n-gram+polynomial meta feats: CV Balanced Accuracy \", cross_val_score(nb_ngram2, countvec_meta_poly_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\nprint(\"Naive Bayes on n-gram+polynomial meta feats: CV AUC Score \", cross_val_score(nb_ngram2, countvec_meta_poly_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\nprint(\"Naive Bayes on n-gram+polynomial meta feats: CV Weighted F1 Score \", cross_val_score(nb_ngram2, countvec_meta_poly_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":32,"outputs":[{"output_type":"stream","text":"Naive Bayes on n-gram+polynomial meta feats: CV Balanced Accuracy  0.37048923875597717\nNaive Bayes on n-gram+polynomial meta feats: CV AUC Score  0.5471220450193515\nNaive Bayes on n-gram+polynomial meta feats: CV Weighted F1 Score  0.46921090807563426\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### NB on tf-idf feats + meta features I created on which polynomial transformation was applied"},{"metadata":{"trusted":true},"cell_type":"code","source":"# tf-idf features + All Meta Features I created with polynomial transformations\ntfidf_meta_poly_features = pd.concat([meta_poly_feats, pd.DataFrame(tfidf_features.toarray())], axis=1)","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"After polynomial transformation, number of features increased from {} to {}\".format(tfidf_meta_features.shape[1], tfidf_meta_poly_features.shape[1]))","execution_count":39,"outputs":[{"output_type":"stream","text":"After polynomial transformation, number of features increased from 1015 to 1136\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_tfidf_meta2 = MultinomialNB()\n\n\nprint(\"Naive Bayes on wfidf+polynomial transformed meta feats: CV Balanced Accuracy \", \n      cross_val_score(nb_tfidf_meta2, tfidf_meta_poly_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\nprint(\"Naive Bayes on wfidf+polynomial transformed meta feats: CV AUC Score \", \n      cross_val_score(nb_tfidf_meta2, tfidf_meta_poly_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\nprint(\"Naive Bayes on wfidf+polynomial transformed meta feats: CV Weighted F1 Score \", \n      cross_val_score(nb_tfidf_meta2, tfidf_meta_poly_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":40,"outputs":[{"output_type":"stream","text":"Naive Bayes on wfidf+polynomial transformed meta feats: CV Balanced Accuracy  0.3701961703893667\nNaive Bayes on wfidf+polynomial transformed meta feats: CV AUC Score  0.5469537358149904\nNaive Bayes on wfidf+polynomial transformed meta feats: CV Weighted F1 Score  0.4690564379517725\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}