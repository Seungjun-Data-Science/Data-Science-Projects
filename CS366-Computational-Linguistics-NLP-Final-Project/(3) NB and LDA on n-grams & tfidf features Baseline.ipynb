{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Import Libraries and Read in Data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/cs366-full-data/data_meta_feat_added_drop_all_missing.csv\", index_col=0)","execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] File b'/kaggle/input/data_meta_feat_added_drop_all_missing.csv' does not exist: b'/kaggle/input/data_meta_feat_added_drop_all_missing.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-8312df782162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/kaggle/input/data_meta_feat_added_drop_all_missing.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'/kaggle/input/data_meta_feat_added_drop_all_missing.csv' does not exist: b'/kaggle/input/data_meta_feat_added_drop_all_missing.csv'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reindex for better / easier concatenation later\ndf.reset_index(inplace=True)\ndel df['index']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare Data for ML (e.g. Countvectorize, split data to train and test data etc.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"del df['url'] # drop url column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n-gram features\n\ncountvec = CountVectorizer(ngram_range=(1,3),max_features=1000,analyzer='word')\ncountvec_features = countvec.fit_transform(df['title'])\nlabels = df['target'].replace({'real':0,'fake':1,'sarcasm':2})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# n-gram features + Meta Features I created\ncountvec_meta_features = pd.concat([df.iloc[:,2:], pd.DataFrame(countvec_features.toarray())], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# wf-idf features (using sublinear_tf = True where wf = 1+ log(tf))\ntfidf = TfidfVectorizer(sublinear_tf = True, ngram_range=(1,3),max_features=1000,analyzer='word')\ntfidf_features = tfidf.fit_transform(df['title'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# wf-idf + Meta Features I created\ntfidf_meta_features = pd.concat([df.iloc[:,2:], pd.DataFrame(tfidf_features.toarray())], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Split into train and test data\n# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Naive Bayes"},{"metadata":{},"cell_type":"markdown","source":"#### Just N-gram features"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_ngram = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Naive Bayes on n-gram features: CV Accuracy \", cross_val_score(nb_ngram, countvec_features, labels, scoring='accuracy', cv=5).mean())\n\nprint(\"Naive Bayes on n-gram features: CV Balanced Accuracy \", cross_val_score(nb_ngram, countvec_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\nprint(\"Naive Bayes on n-gram features: CV AUC Score \", cross_val_score(nb_ngram, countvec_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\nprint(\"Naive Bayes on n-gram features: CV Weighted F1 Score \", cross_val_score(nb_ngram, countvec_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### N-gram features + Meta Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_ngram_meta = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Naive Bayes on n-gram+meta feats: CV Accuracy \", \n      cross_val_score(nb_ngram_meta, countvec_meta_features, labels, scoring='accuracy', cv=5).mean())\n\nprint(\"Naive Bayes on n-gram+meta feats: CV Balanced Accuracy \", \n      cross_val_score(nb_ngram_meta, countvec_meta_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\nprint(\"Naive Bayes on n-gram+meta feats: CV AUC Score \", \n      cross_val_score(nb_ngram_meta, countvec_meta_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\nprint(\"Naive Bayes on n-gram+meta feats: CV Weighted F1 Score \", \n      cross_val_score(nb_ngram_meta, countvec_meta_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### TF-IDF Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_tfidf = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Naive Bayes on wfidf feats: CV Accuracy \", \n      cross_val_score(nb_tfidf, tfidf_features, labels, scoring='accuracy', cv=5).mean())\n\nprint(\"Naive Bayes on wfidf feats: CV Balanced Accuracy \", \n      cross_val_score(nb_tfidf, tfidf_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\nprint(\"Naive Bayes on wfidf feats: CV AUC Score \", \n      cross_val_score(nb_tfidf, tfidf_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\nprint(\"Naive Bayes on wfidf feats: CV Weighted F1 Score \", \n      cross_val_score(nb_tfidf, tfidf_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### TF-IDF Features + Meta Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_tfidf_meta = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Naive Bayes on wfidf+meta feats: CV Accuracy \", \n      cross_val_score(nb_tfidf_meta, tfidf_meta_features, labels, scoring='accuracy', cv=5).mean())\n\nprint(\"Naive Bayes on wfidf+meta feats: CV Balanced Accuracy \", \n      cross_val_score(nb_tfidf_meta, tfidf_meta_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\nprint(\"Naive Bayes on wfidf+meta feats: CV AUC Score \", \n      cross_val_score(nb_tfidf_meta, tfidf_meta_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\nprint(\"Naive Bayes on wfidf+meta feats: CV Weighted F1 Score \", \n      cross_val_score(nb_tfidf_meta, tfidf_meta_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"# stdscaler = StandardScaler(with_mean=False)\n# countvec_features_scaled = stdscaler.fit_transform(countvec_features)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### N-gram features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lr_ngram = LogisticRegression(multi_class='multinomial', max_iter=500)\n\n# print(\"Logistic Regression on n-gram features: CV Accuracy \", cross_val_score(lr_ngram, countvec_features, labels, scoring='accuracy', cv=5).mean())\n\n# print(\"Logistic Regression on n-gram features: CV Balanced Accuracy \", cross_val_score(lr_ngram, countvec_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\n# print(\"Logistic Regression on n-gram features: CV AUC Score \", cross_val_score(lr_ngram, countvec_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\n# print(\"Logistic Regression on n-gram features: CV Weighted F1 Score \", cross_val_score(lr_ngram, countvec_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### n-gram + meta features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# stdscaler = StandardScaler(with_mean=False)\n# countvec_meta_features_scaled = stdscaler.fit_transform(countvec_meta_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lr_ngram_meta = LogisticRegression(multi_class='multinomial', max_iter=1000)\n\n# print(\"Logistic Regression on n-gram+meta feats: CV Accuracy \", \n#       cross_val_score(lr_ngram_meta, countvec_meta_features_scaled, labels, scoring='accuracy', cv=5).mean())\n\n# print(\"Logistic Regression on n-gram+meta feats: CV Balanced Accuracy \", \n#       cross_val_score(lr_ngram_meta, countvec_meta_features_scaled, labels, scoring='balanced_accuracy', cv=5).mean())\n\n# print(\"Logistic Regression on n-gram+meta feats: CV AUC Score \", \n#       cross_val_score(lr_ngram_meta, countvec_meta_features_scaled, labels, scoring='roc_auc_ovr', cv=5).mean())\n\n# print(\"Logistic Regression on n-gram+meta feats: CV Weighted F1 Score \", \n#       cross_val_score(lr_ngram_meta, countvec_meta_features_scaled, labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### TF-IDF features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lr_tfidf = LogisticRegression(multi_class='multinomial', max_iter=500)\n\n# print(\"Logistic Regression on wfidf feats: CV Accuracy \", \n#       cross_val_score(lr_tfidf, tfidf_features, labels, scoring='accuracy', cv=5).mean())\n\n# print(\"Logistic Regression on wfidf feats: CV Balanced Accuracy \", \n#       cross_val_score(lr_tfidf, tfidf_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\n# print(\"Logistic Regression on wfidf feats: CV AUC Score \", \n#       cross_val_score(lr_tfidf, tfidf_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\n# print(\"Logistic Regression on wfidf feats: CV Weighted F1 Score \", \n#       cross_val_score(lr_tfidf, tfidf_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### TF-IDF + meta features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lr_tfidf_meta = LogisticRegression(multi_class='multinomial', max_iter=500)\n\n# print(\"Logistic Regression on wfidf+meta feats: CV Accuracy \", \n#       cross_val_score(lr_tfidf_meta, tfidf_meta_features, labels, scoring='accuracy', cv=5).mean())\n\n# print(\"Logistic Regression on wfidf+meta feats: CV Balanced Accuracy \", \n#       cross_val_score(lr_tfidf_meta, tfidf_meta_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\n# print(\"Logistic Regression on wfidf+meta feats: CV AUC Score \", \n#       cross_val_score(lr_tfidf_meta, tfidf_meta_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\n# print(\"Logistic Regression on wfidf+meta feats: CV Weighted F1 Score \", \n#       cross_val_score(lr_tfidf_meta, tfidf_meta_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### QuadraticDiscriminantAnalysis"},{"metadata":{},"cell_type":"markdown","source":"#### N-gram features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# qda_ngram = QuadraticDiscriminantAnalysis()\n\n# print(\"QuadraticDiscriminantAnalysis on n-gram features: CV Accuracy \", \n#       cross_val_score(qda_ngram, countvec_features.toarray(), labels, scoring='accuracy', cv=5).mean())\n\n# print(\"QuadraticDiscriminantAnalysis on n-gram features: CV Balanced Accuracy \", \n#       cross_val_score(qda_ngram, countvec_features.toarray(), labels, scoring='balanced_accuracy', cv=5).mean())\n\n# print(\"QuadraticDiscriminantAnalysis on n-gram features: CV AUC Score \", \n#       cross_val_score(qda_ngram, countvec_features.toarray(), labels, scoring='roc_auc_ovr', cv=5).mean())\n\n# print(\"QuadraticDiscriminantAnalysis on n-gram features: CV Weighted F1 Score \", \n#       cross_val_score(qda_ngram, countvec_features.toarray(), labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### N-gram + meta features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# qda_ngram_meta = QuadraticDiscriminantAnalysis()\n\n# print(\"QuadraticDiscriminantAnalysis on n-gram+meta feats: CV Accuracy \", \n#       cross_val_score(qda_ngram_meta, countvec_meta_features.values, labels, scoring='accuracy', cv=5).mean())\n\n# print(\"QuadraticDiscriminantAnalysis on n-gram+meta feats: CV Balanced Accuracy \", \n#       cross_val_score(qda_ngram_meta, countvec_meta_features.values, labels, scoring='balanced_accuracy', cv=5).mean())\n\n# print(\"QuadraticDiscriminantAnalysis on n-gram+meta feats: CV AUC Score \", \n#       cross_val_score(qda_ngram_meta, countvec_meta_features.values, labels, scoring='roc_auc_ovr', cv=5).mean())\n\n# print(\"QuadraticDiscriminantAnalysis on n-gram+meta feats: CV Weighted F1 Score \", \n#       cross_val_score(qda_ngram_meta, countvec_meta_features.values, labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### TF-IDF features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# qda_tfidf = QuadraticDiscriminantAnalysis()\n\n# print(\"QuadraticDiscriminantAnalysis on wfidf feats: CV Accuracy \", \n#       cross_val_score(qda_tfidf, tfidf_features.toarray(), labels, scoring='accuracy', cv=5).mean())\n\n# print(\"QuadraticDiscriminantAnalysis on wfidf feats: CV Balanced Accuracy \", \n#       cross_val_score(qda_tfidf, tfidf_features.toarray(), labels, scoring='balanced_accuracy', cv=5).mean())\n\n# print(\"QuadraticDiscriminantAnalysis on wfidf feats: CV AUC Score \", \n#       cross_val_score(qda_tfidf, tfidf_features.toarray(), labels, scoring='roc_auc_ovr', cv=5).mean())\n\n# print(\"QuadraticDiscriminantAnalysis on wfidf feats: CV Weighted F1 Score \", \n#       cross_val_score(qda_tfidf, tfidf_features.toarray(), labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### TF-IDF + meta features"},{"metadata":{"trusted":true},"cell_type":"code","source":"# qda_tfidf_meta = QuadraticDiscriminantAnalysis()\n\n# print(\"QuadraticDiscriminantAnalysis on wfidf+meta feats: CV Accuracy \", \n#       cross_val_score(qda_tfidf_meta, tfidf_meta_features, labels, scoring='accuracy', cv=5).mean())\n\n# print(\"QuadraticDiscriminantAnalysis on wfidf+meta feats: CV Balanced Accuracy \", \n#       cross_val_score(qda_tfidf_meta, tfidf_meta_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\n# print(\"QuadraticDiscriminantAnalysis on wfidf+meta feats: CV AUC Score \", \n#       cross_val_score(qda_tfidf_meta, tfidf_meta_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\n# print(\"QuadraticDiscriminantAnalysis on wfidf+meta feats: CV Weighted F1 Score \", \n#       cross_val_score(qda_tfidf_meta, tfidf_meta_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Linear Discriminant Analysis"},{"metadata":{},"cell_type":"markdown","source":"#### N-gram features"},{"metadata":{"trusted":true},"cell_type":"code","source":"lda_ngram = LinearDiscriminantAnalysis()\n\nprint(\"LinearDiscriminantAnalysis on n-gram features: CV Accuracy \", \n      cross_val_score(lda_ngram, countvec_features.toarray(), labels, scoring='accuracy', cv=5).mean())\n\nprint(\"LinearDiscriminantAnalysis on n-gram features: CV Balanced Accuracy \", \n      cross_val_score(lda_ngram, countvec_features.toarray(), labels, scoring='balanced_accuracy', cv=5).mean())\n\nprint(\"LinearDiscriminantAnalysis on n-gram features: CV AUC Score \", \n      cross_val_score(lda_ngram, countvec_features.toarray(), labels, scoring='roc_auc_ovr', cv=5).mean())\n\nprint(\"LinearDiscriminantAnalysis on n-gram features: CV Weighted F1 Score \", \n      cross_val_score(lda_ngram, countvec_features.toarray(), labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### N-gram + meta features"},{"metadata":{"trusted":true},"cell_type":"code","source":"lda_ngram_meta = LinearDiscriminantAnalysis()\n\nprint(\"LinearDiscriminantAnalysis on n-gram+meta feats: CV Accuracy \", \n      cross_val_score(lda_ngram_meta, countvec_meta_features, labels, scoring='accuracy', cv=5).mean())\n\nprint(\"LinearDiscriminantAnalysis on n-gram+meta feats: CV Balanced Accuracy \", \n      cross_val_score(lda_ngram_meta, countvec_meta_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\nprint(\"LinearDiscriminantAnalysis on n-gram+meta feats: CV AUC Score \", \n      cross_val_score(lda_ngram_meta, countvec_meta_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\nprint(\"LinearDiscriminantAnalysis on n-gram+meta feats: CV Weighted F1 Score \", \n      cross_val_score(lda_ngram_meta, countvec_meta_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### TF-IDF features"},{"metadata":{"trusted":true},"cell_type":"code","source":"lda_tfidf = LinearDiscriminantAnalysis()\n\nprint(\"LinearDiscriminantAnalysis on wfidf feats: CV Accuracy \", \n      cross_val_score(lda_tfidf, tfidf_features.toarray(), labels, scoring='accuracy', cv=5).mean())\n\nprint(\"LinearDiscriminantAnalysis on wfidf feats: CV Balanced Accuracy \", \n      cross_val_score(lda_tfidf, tfidf_features.toarray(), labels, scoring='balanced_accuracy', cv=5).mean())\n\nprint(\"LinearDiscriminantAnalysis on wfidf feats: CV AUC Score \", \n      cross_val_score(lda_tfidf, tfidf_features.toarray(), labels, scoring='roc_auc_ovr', cv=5).mean())\n\nprint(\"LinearDiscriminantAnalysis on wfidf feats: CV Weighted F1 Score \", \n      cross_val_score(lda_tfidf, tfidf_features.toarray(), labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### TF-IDF + Meta features"},{"metadata":{"trusted":true},"cell_type":"code","source":"lda_tfidf_meta = LinearDiscriminantAnalysis()\n\nprint(\"LinearDiscriminantAnalysis on wfidf+meta feats: CV Accuracy \", \n      cross_val_score(lda_tfidf_meta, tfidf_meta_features, labels, scoring='accuracy', cv=5).mean())\n\nprint(\"LinearDiscriminantAnalysis on wfidf+meta feats: CV Balanced Accuracy \", \n      cross_val_score(lda_tfidf_meta, tfidf_meta_features, labels, scoring='balanced_accuracy', cv=5).mean())\n\nprint(\"LinearDiscriminantAnalysis on wfidf+meta feats: CV AUC Score \", \n      cross_val_score(lda_tfidf_meta, tfidf_meta_features, labels, scoring='roc_auc_ovr', cv=5).mean())\n\nprint(\"LinearDiscriminantAnalysis on wfidf+meta feats: CV Weighted F1 Score \", \n      cross_val_score(lda_tfidf_meta, tfidf_meta_features, labels, scoring='f1_weighted', cv=5).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some issues encountered in other algorithms\n\n- Convergence issue in Logistic Regression \n- Too much computational cost for QDA (kernel die) + collinearity"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}