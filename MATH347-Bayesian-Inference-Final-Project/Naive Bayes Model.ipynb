{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_17_18_df = pd.read_csv(\"player_17_18_stats.csv\")\n",
    "player_18_19_df = pd.read_csv(\"player_18_19_stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del player_17_18_df['Unnamed: 0']\n",
    "del player_18_19_df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_17_18_df = player_17_18_df.dropna(how=\"any\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_18_19_df.all_star_bool = np.where(player_18_19_df.all_star_bool.isnull(), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cols = [c for c in player_17_18_df.columns if c not in ['Rk','Player','all_star_bool']]\n",
    "correlations = player_17_18_df[cols].corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\n",
    "correlations = correlations[correlations['level_0'] != correlations['level_1']]\n",
    "correlations.columns = ['feature1', 'feature2', 'correlation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correlations = correlations.drop_duplicates('correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = \\\n",
    "list(set(correlations[correlations.correlation > 0.7].feature1.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlations2 = player_17_18_df[cols].drop(labels=remove_cols,axis=1).\\\n",
    "corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\n",
    "correlations2 = correlations2[correlations2['level_0'] != correlations2['level_1']]\n",
    "correlations2.columns = ['feature1', 'feature2', 'correlation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(correlations2.feature1.tolist() + correlations2.feature2.tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_cols = list(set(correlations2.feature1.tolist() + correlations2.feature2.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = player_17_18_df[new_cols].values\n",
    "y = player_17_18_df.all_star_bool.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = player_18_19_df[new_cols].values\n",
    "y_test = player_18_19_df.all_star_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.99       682\n",
      "          1       0.61      0.85      0.71        26\n",
      "\n",
      "avg / total       0.98      0.97      0.98       708\n",
      "\n",
      "[[668  14]\n",
      " [  4  22]]\n",
      "accuracy is 0.9745762711864406\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(X, y)\n",
    "\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Accuracy score\n",
    "print('accuracy is',accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes when you don't remove any correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = player_17_18_df[cols].values\n",
    "y2 = player_17_18_df.all_star_bool.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = player_18_19_df[cols].values\n",
    "y_test2 = player_18_19_df.all_star_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.93      0.96       682\n",
      "          1       0.33      0.92      0.48        26\n",
      "\n",
      "avg / total       0.97      0.93      0.94       708\n",
      "\n",
      "[[633  49]\n",
      " [  2  24]]\n",
      "accuracy is 0.9279661016949152\n"
     ]
    }
   ],
   "source": [
    "gnb2 = GaussianNB()\n",
    "gnb2.fit(X2, y2)\n",
    "\n",
    "y_pred2 = gnb2.predict(X_test2)\n",
    "\n",
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test2, y_pred2))\n",
    "print(confusion_matrix(y_test2, y_pred2))\n",
    "\n",
    "# Accuracy score\n",
    "print('accuracy is',accuracy_score(y_pred2,y_test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which Feature is most important? Features that have high variability for each class are important because higher sigma maximizes the conditional probability of x_i given y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['2P', 'FTA', 'AST', '3PA', 'DRB', 'TRB', 'FGA', '2PA', 'MP', 'PTS'], dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 important features for model with all the features\n",
    "player_17_18_df[new_cols].columns[gnb2.sigma_[1,:].argsort()][-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Points, Minutes Played, 2 Point Goals Attempted, Field Goals Attempted, Total Rebounds, Defensive Rebounds..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FG', 'MP', 'G', 'FGA', '3PA', '2P', '2PA', 'GS', 'Age', '3P'], dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 important features for model with uncorrelated features\n",
    "player_17_18_df[cols].columns[gnb.sigma_[1,:].argsort()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Points, Age, Games Started, 2 Point Goals Attempted, 2 Point Goals, 3 Point Goals Attempted..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Classifiers (v.s. Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression (without any hyperparameter Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = player_17_18_df[cols].values\n",
    "y3 = player_17_18_df.all_star_bool.values\n",
    "\n",
    "X_test3 = player_18_19_df[cols].values\n",
    "y_test3 = player_18_19_df.all_star_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lgr = LogisticRegression()\n",
    "lgr.fit(X3, y3)\n",
    "\n",
    "y_pred3 = lgr.predict(X_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.98      0.99       682\n",
      "          1       0.64      0.81      0.71        26\n",
      "\n",
      "avg / total       0.98      0.98      0.98       708\n",
      "\n",
      "[[670  12]\n",
      " [  5  21]]\n",
      "accuracy is 0.9759887005649718\n"
     ]
    }
   ],
   "source": [
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test3, y_pred3))\n",
    "print(confusion_matrix(y_test3, y_pred3))\n",
    "\n",
    "# Accuracy score\n",
    "print('accuracy is',accuracy_score(y_pred3,y_test3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree Classifier (without any hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4 = player_17_18_df[cols].values\n",
    "y4 = player_17_18_df.all_star_bool.values\n",
    "\n",
    "X_test4 = player_18_19_df[cols].values\n",
    "y_test4 = player_18_19_df.all_star_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(X4, y4)\n",
    "y_pred4 = dtc.predict(X_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.99      0.99       682\n",
      "          1       0.74      0.65      0.69        26\n",
      "\n",
      "avg / total       0.98      0.98      0.98       708\n",
      "\n",
      "[[676   6]\n",
      " [  9  17]]\n",
      "accuracy is 0.9788135593220338\n"
     ]
    }
   ],
   "source": [
    "# Summary of the predictions made by the classifier\n",
    "print(classification_report(y_test4, y_pred4))\n",
    "print(confusion_matrix(y_test4, y_pred4))\n",
    "\n",
    "# Accuracy score\n",
    "print('accuracy is',accuracy_score(y_pred4,y_test4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
